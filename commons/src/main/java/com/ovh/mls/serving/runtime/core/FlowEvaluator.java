package com.ovh.mls.serving.runtime.core;

import com.ovh.mls.serving.runtime.core.io.TensorIO;
import com.ovh.mls.serving.runtime.exceptions.EvaluationException;
import com.ovh.mls.serving.runtime.exceptions.EvaluatorException;
import com.ovh.mls.serving.runtime.validation.Validator;
import org.apache.commons.collections4.SetUtils;

import java.io.IOException;
import java.util.ArrayList;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Set;
import java.util.stream.Collectors;

public class FlowEvaluator implements Evaluator {
    private final List<Field> inputs;
    private final List<Field> outputs;
    private final int rollingWindowsSize;
    private final List<Evaluator> evaluators;

    private FlowEvaluator(List<Evaluator> evaluators, List<Field> inputs, List<Field> outputs, int rollingWindowsSize) {
        this.evaluators = evaluators;
        this.inputs = inputs;
        this.outputs = outputs;
        this.rollingWindowsSize = rollingWindowsSize;
    }

    /**
     * Instantiate a FlowEvaluator based on its manifest and instantiate and validate all underlying evaluators.
     * In doing so the create function also infers what are the global required inputs to evaluate the FlowEvaluator,
     * what is the required batch size (number of points (or rows)) to perform an evaluation and finally if outputs
     * are specified in the manifest then their generation is checked and if not outputs are set to the Fields that
     * are generated but never used as inputs.
     *
     * @param flowEvaluatorManifest Manifest with the definition of the flow and the underlying evaluators
     * @param path
     * @return validated instance of the FlowEvaluator
     * @throws EvaluatorException if there are some initialization errors such as failed validation or input/output
     *                            discrepancies
     */
    public static FlowEvaluator create(FlowEvaluatorManifest flowEvaluatorManifest, String path)
        throws EvaluatorException, IOException {

        List<EvaluatorManifest> evaluatorManifests = flowEvaluatorManifest.getEvaluatorManifests();

        List<Evaluator> evaluators = new ArrayList<>(evaluatorManifests.size());
        Set<Field> pureInputSet = new HashSet<>();
        Set<Field> inputSet = new HashSet<>();
        Set<Field> outputSet = new HashSet<>();
        int batchSize = 1;

        for (EvaluatorManifest evaluatorManifest : evaluatorManifests) {

            // instantiate evaluators
            Evaluator evaluator = evaluatorManifest.create(path);
            Validator.validate(evaluator);
            evaluators.add(evaluator);

            // compute pure inputs
            pureInputSet.addAll(
                // We only set as inputs fields that are not generated by any evaluators so far
                SetUtils.difference(new HashSet<>(evaluator.getInputs()), outputSet)
            );

            // aggregate all inputs
            inputSet.addAll(evaluator.getInputs());

            // We keep track of generated outputs
            outputSet.addAll(evaluator.getOutputs());

            // compute global batch size, evaluators computed over several rows are applied as window operations
            // if a subsequent evaluator do not rely on previous evaluator results then the batch size need not be
            // added, this case is not handle for now and the computed batch size is an upper bound of the minimum one
            // required
            batchSize += evaluator.getRollingWindowSize() - 1;
        }

        List<Field> actualOutputs;
        if (!flowEvaluatorManifest.getOutputs().isEmpty()) {
            actualOutputs = flowEvaluatorManifest.getOutputs();
            SetUtils.SetView<Field> difference = SetUtils.difference(new HashSet<>(actualOutputs), outputSet);
            if (!difference.isEmpty()) {
                throw new EvaluatorException(
                    String.format(
                        "Desired outputs %s are not actual outputs of the described FlowEvaluator",
                        difference.stream().map(Field::getName).collect(Collectors.joining(","))
                    )
                );
            }
        } else {
            // If no outputs are specified, the output of the last evaluator is used
            if (evaluators.isEmpty()) {
                actualOutputs = new LinkedList<>();
            } else {
                actualOutputs = evaluators.get(evaluators.size() - 1).getOutputs();
            }
        }

        return new FlowEvaluator(evaluators, new LinkedList<>(pureInputSet), actualOutputs, batchSize);
    }

    @Override
    public TensorIO evaluate(TensorIO io, EvaluationContext evaluationContext)
        throws EvaluationException {

        if (io.getBatchSize() < rollingWindowsSize) {
            throw new EvaluationException(
                String.format("Not enough data to evaluate. Required batch size is %d", rollingWindowsSize)
            );
        }

        TensorIO lastIO = new TensorIO();
        lastIO.merge(io);
        for (Evaluator evaluator : evaluators) {
            lastIO.merge(evaluator.evaluate(lastIO, evaluationContext));
            evaluationContext.incCurrentEvaluator();
        }

        // Retain only needed outputs fields
        lastIO.retainFields(outputs);

        // Count how many times we have call the model.
        evaluationContext.incEvaluationBy(lastIO.getBatchSize());

        return lastIO;
    }

    @Override
    public List<Field> getInputs() {
        return inputs;
    }

    @Override
    public List<Field> getOutputs() {
        return outputs;
    }

    @Override
    public int getRollingWindowSize() {
        return rollingWindowsSize;
    }

}
